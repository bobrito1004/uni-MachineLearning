{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DT_test.ipynb","provenance":[{"file_id":"1IAJXJC3FAdrLQnl2yVoEvX8jg27CzLm6","timestamp":1603282414216}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hGClrhQA9SAk"},"source":["# Деревья решений"]},{"cell_type":"markdown","metadata":{"id":"veekMy8WRjBi"},"source":["## Построение дерева"]},{"cell_type":"markdown","metadata":{"id":"SYkVwAFiUHXj"},"source":["Опишем жадный алгоритм построения бинарного дерева решений:\n","1. Начинаем со всей обучающей выборки $X$, которую помещаем в корень $R_1$. \n","2. Задаём функционал качества $Q(X, j, t)$ и критерий остановки. \n","3. Запускаем построение из корня: $SplitNode(1, R_1)$\n","\n","Функция $SplitNode(m, R_m)$\n","1. Если выполнен критерий остановки, то выход.\n","2. Находим наилучший с точки зрения $Q$ предикат: $j, t$: $[x_j<t]$\n","3. Помещаем предикат в вкршину и получаем с его помощью разбиение $X$ на две части: $R_{left} = \\lbrace x|x_j<t \\rbrace$ и $R_{right} = \\lbrace x|x_j \\geqslant t \\rbrace$\n","4. Поместим $R_{left}$ и $R_{right}$ соответсвенно в левое и правое поддерево.\n","5. Рекурсивно повторяем $SplitNode(left, R_{left})$ и $SplitNode(right, R_{right})$.\n","\n","В конце поставим в соответствие каждому листу ответ. Для задачи классификации - это самый частый среди объектов класс или вектор с долями классов (можно интерпретировать как вероятности):\n","$$ c_v = \\arg \\max_{k\\in Y} \\sum_{(x_i,y_i) \\in R_v} [y_i=k]  $$"]},{"cell_type":"markdown","metadata":{"id":"9P6FsdBog4Ai"},"source":["## Функционал качества для деревьев решений\n"]},{"cell_type":"markdown","metadata":{"id":"9VAKO0aykGBD"},"source":["Энтропия Шеннона для системы с N возможными состояниями определяется по формуле:\n","$$H = - \\sum_{i=0}^{N} p_i\\log_2p_i $$"]},{"cell_type":"markdown","metadata":{"id":"5582B-1Fn2bw"},"source":["где $p_i$ – вероятности нахождения системы в $i$-ом состоянии. \n","\n","Это очень важное понятие теории информации, которое позволяет оценить количество информации (степень хаоса в системе). Чем выше энтропия, тем менее упорядочена система и наоборот. С помощью энтропии мы формализуем функционал качества для разделение выборки (для задачи классификации)."]},{"cell_type":"code","metadata":{"id":"PbcMUd7bvk05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637833469910,"user_tz":-180,"elapsed":784,"user":{"displayName":"Алексей Бабинцев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16114735127853103545"}},"outputId":"a0d997ee-3d1d-4f70-98c3-a2682e23462a"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import random\n","from pprint import pprint\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import statistics\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","from sklearn.tree import DecisionTreeClassifier\n","from category_encoders import TargetEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}]},{"cell_type":"code","metadata":{"id":"52R9Cs6mGj7x"},"source":["#pip install category_encoders"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4AdLxP9CowTm"},"source":["Код для расчёта энтропии:"]},{"cell_type":"code","metadata":{"id":"2mT8Jq8Av2sM"},"source":["def entropy(y):\n","    \n","    _, counts = np.unique(y, return_counts=True)\n","\n","    probabilities = counts / counts.sum()\n","    entropy = sum(probabilities * -np.log2(probabilities))\n","     \n","    return entropy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xk9etb2vo7fK"},"source":["Здесь $y$ - это массив значений целевой переменной"]},{"cell_type":"markdown","metadata":{"id":"07TCw0USzLus"},"source":["Энтропия – по сути степень хаоса (или неопределенности) в системе. Уменьшение энтропии называют приростом информации (information gain, IG).\n","\n","Обочначим $R_v$ - объекты, которые нужно разделить в помощью предиката в вершине $v$. Запишем формулу для расчёта информационного прироста:\n","$$ Q = IG = H(R_v) - (H(R_{left})+H(R_{right}))$$\n","\n","На каждом шаге нам нужно максимизировать этот функционал качества. Как это делать? Например, так можно перебрать $t$ для выбранного $j$."]},{"cell_type":"markdown","metadata":{"id":"trEWHDoXg_p9"},"source":["Предыдущая версия формулы прироста информации слишком упрощена. В работе необходимо использовать более устойчивую формулу, которая учитывает не только энтропию подмножеств, но и их размер. \n","\n","$$ Q = IG = H(R_v) - \\Big (\\frac{|R_{left}|} {|R_{v}|} H(R_{left})+ \\frac{|R_{right}|} {|R_{v}|} H(R_{right})\\Big)$$\n","\n","где, $|R_{v}|$, $|R_{left}|$ и $|R_{right}|$ - количество элементов в соответствующих множествах."]},{"cell_type":"markdown","metadata":{"id":"9xmN6V_N1xBr"},"source":["\n","### Задание 4.1"]},{"cell_type":"markdown","metadata":{"id":"nWFHZScF2CBF"},"source":["Реализуйте алгоритм построения дерева. Должны быть отдельные функции (методы) для расчёта энтропии (уже есть), для разделения дерева (используйте `pandas`), для подсчёта функционала качества $IG$, для выбора наилучшего разделения (с учетом признакоd и порогов), для проверки критерия остановки.\n","\n","Для набора данных `iris` реализуйте алгоритм и минимум три из разными критерия остановки из перечисленных ниже:\n","* максимальной глубины дерева = 5\n","* минимального числа объектов в листе = 5\n","* максимальное количество листьев в дереве = 5\n","* purity (остановка, если все объекты в листе относятся к одному классу)\n","\n","Реализуйте функцию `predict` (на вход функции подаётся датафрейм с объектами)\n","\n","Оцените точность каждой модели с помощью метрики точность (`from sklearn.metrics import accuracy_score` или реализовать свою)."]},{"cell_type":"code","metadata":{"id":"pbmjFOJ-0Lo_"},"source":["class Node:\n","  def __init__(self):\n","    self.R = None\n","    self.L = None\n","    self.classP = None\n","    self.col = None\n","    self.value = -1\n","    self.leaf = False\n","\n","\n","class DT:\n","  def __init__(self, depth, minS):\n","    self.tree = None\n","    self.depth = depth\n","    self.nowD = 0\n","    self.minS = minS\n","    self.y_train = None\n","  def findClass(self, x_test, node):\n","    if node.leaf:\n","      return node.classP\n","    elif x_test[node.col] > node.value:\n","      return self.findClass(x_test, node.R)\n","    else:\n","      return self.findClass(x_test, node.L)\n","  def fit(self, x_train, y_train):\n","    self.y_train = y_train\n","    self.tree = Node()\n","    self.tree.classP = self.calcClassP(y_train)\n","    self.SplitNode(np.asarray(x_train), y_train, self.tree)\n","  def predict(self, x_test):\n","    y_pred = np.array([])\n","    for x in np.asarray(x_test):\n","      y_pred = np.append(y_pred, np.argmax(self.findClass(x, self.tree)))\n","    return y_pred\n","  def SplitNode(self, x_train, y_train, node):\n","    if self.nowD >= self.depth or len(np.unique(y_train)) == 1:\n","      node.leaf = True\n","      return\n","    bestFeature = None\n","    bestT = None\n","    bestEntropy = -1\n","    bestSampleL = []\n","    bestSampleR = []\n","    xL = []\n","    xR = []\n","    for feature in range(x_train.shape[1]):\n","      xFeature = x_train[:, feature]\n","      for value in xFeature:\n","        sampleL = y_train[xFeature <= value]\n","        sampleR = y_train[xFeature > value]\n","        if len(sampleL) == 0 or len(sampleR) == 0:\n","          continue\n","        entropyVal = entropy(y_train) - (\n","            (len(sampleL) / len(y_train) * entropy(sampleL)) + (\n","                len(sampleR) / len(y_train)*entropy(sampleR)))\n","        if entropyVal > bestEntropy:\n","          bestT = value\n","          bestEntropy = entropyVal\n","          bestSampleL = sampleL\n","          bestSampleR = sampleR\n","          bestCol = feature\n","          xL = x_train[xFeature <= value, :]\n","          xR = x_train[xFeature > value, :]\n","          xFeature = x_train[:, bestCol]\n","      if len(xL) < self.minS or len(xR) < self.minS:\n","        node.leaf = True\n","        return\n","    self.nowD += 1\n","    node.L = Node()\n","    node.L.classP = self.calcClassP(bestSampleL)\n","    node.R = Node()\n","    node.R.classP = self.calcClassP(bestSampleR)\n","    node.col = bestCol\n","    node.value = bestT\n","    self.SplitNode(xL, bestSampleL, node.L)\n","    self.SplitNode(xR, bestSampleR, node.R)\n","  def calcClassP(self, data):\n","    result = np.array([])\n","    for type_ in np.unique(self.y_train):\n","      result = np.append(result, len(data[data == type_]) / len(data))\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXCsSih2B8my"},"source":["class DT1:\n","  def __init__(self, depth, minS):\n","    self.tree = None\n","    self.depth = depth\n","    self.nowD = 0\n","    self.minS = minS\n","    self.y_train = None\n","  def findClass(self, x_test, node):\n","    if node.leaf:\n","      return node.classP\n","    elif x_test[node.col] > node.value:\n","      return self.findClass(x_test, node.R)\n","    else:\n","      return self.findClass(x_test, node.L)\n","  def fit(self, x_train, y_train):\n","    self.y_train = y_train\n","    self.tree = Node()\n","    self.tree.classP = self.calcClassP(y_train)\n","    self.SplitNode(np.asarray(x_train), y_train, self.tree)\n","  def predict(self, x_test):\n","    y_pred = np.array([])\n","    for x in np.asarray(x_test):\n","      y_pred = np.append(y_pred, np.argmax(self.findClass(x, self.tree)))\n","    return y_pred\n","  def SplitNode(self, x_train, y_train, node):\n","    if self.nowD >= self.depth or len(np.unique(y_train)) == 1:\n","      node.leaf = True\n","      return\n","    bestFeature = None\n","    bestT = None\n","    bestEntropy = -1\n","    bestSampleL = []\n","    bestSampleR = []\n","    xL = []\n","    xR = []\n","    for feature in range(x_train.shape[1]):\n","      xFeature = x_train[:, feature]\n","      for value in xFeature:\n","        sampleL = y_train[xFeature <= value]\n","        sampleR = y_train[xFeature > value]\n","        if len(sampleL) == 0 or len(sampleR) == 0:\n","          continue\n","        entropyVal = entropy(y_train) - (\n","            (len(sampleL) / len(y_train) * entropy(sampleL)) + (\n","                len(sampleR) / len(y_train)*entropy(sampleR)))\n","        if entropyVal > bestEntropy:\n","          bestT = value\n","          bestEntropy = entropyVal\n","          bestSampleL = sampleL\n","          bestSampleR = sampleR\n","          bestCol = feature\n","          xL = x_train[xFeature <= value, :]\n","          xR = x_train[xFeature > value, :]\n","          xFeature = x_train[:, bestCol]\n","      if len(xL) < self.minS or len(xR) < self.minS:\n","        node.leaf = True\n","        return\n","    self.nowD += 1\n","    node.L = Node()\n","    node.L.classP = self.calcClassP(bestSampleL)\n","    node.R = Node()\n","    node.R.classP = self.calcClassP(bestSampleR)\n","    node.col = bestCol\n","    node.value = bestT\n","    self.SplitNode(xL, bestSampleL, node.L)\n","    self.SplitNode(xR, bestSampleR, node.R)\n","  def calcClassP(self, data):\n","    result = np.array([])\n","    for type_ in np.unique(self.y_train):\n","      result = np.append(result, len(data[data == type_]) / len(data))\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZGzlJcXB_ze"},"source":["class DT2:\n","  def __init__(self, depth, minS):\n","    self.tree = None\n","    self.depth = depth\n","    self.nowD = 0\n","    self.minS = minS\n","    self.y_train = None\n","  def findClass(self, x_test, node):\n","    if node.leaf:\n","      return node.classP\n","    elif x_test[node.col] > node.value:\n","      return self.findClass(x_test, node.R)\n","    else:\n","      return self.findClass(x_test, node.L)\n","  def fit(self, x_train, y_train):\n","    self.y_train = y_train\n","    self.tree = Node()\n","    self.tree.classP = self.calcClassP(y_train)\n","    self.SplitNode(np.asarray(x_train), y_train, self.tree)\n","  def predict(self, x_test):\n","    y_pred = np.array([])\n","    for x in np.asarray(x_test):\n","      y_pred = np.append(y_pred, np.argmax(self.findClass(x, self.tree)))\n","    return y_pred\n","  def SplitNode(self, x_train, y_train, node):\n","    if self.nowD >= self.depth or len(np.unique(y_train)) == 1:\n","      node.leaf = True\n","      return\n","    bestFeature = None\n","    bestT = None\n","    bestEntropy = -1\n","    bestSampleL = []\n","    bestSampleR = []\n","    xL = []\n","    xR = []\n","    for feature in range(x_train.shape[1]):\n","      xFeature = x_train[:, feature]\n","      for value in xFeature:\n","        sampleL = y_train[xFeature <= value]\n","        sampleR = y_train[xFeature > value]\n","        if len(sampleL) == 0 or len(sampleR) == 0:\n","          continue\n","        entropyVal = entropy(y_train) - (\n","            (len(sampleL) / len(y_train) * entropy(sampleL)) + (\n","                len(sampleR) / len(y_train)*entropy(sampleR)))\n","        if entropyVal > bestEntropy:\n","          bestT = value\n","          bestEntropy = entropyVal\n","          bestSampleL = sampleL\n","          bestSampleR = sampleR\n","          bestCol = feature\n","          xL = x_train[xFeature <= value, :]\n","          xR = x_train[xFeature > value, :]\n","          xFeature = x_train[:, bestCol]\n","      if len(xL) < self.minS or len(xR) < self.minS:\n","        node.leaf = True\n","        return\n","    self.nowD += 1\n","    node.L = Node()\n","    node.L.classP = self.calcClassP(bestSampleL)\n","    node.R = Node()\n","    node.R.classP = self.calcClassP(bestSampleR)\n","    node.col = bestCol\n","    node.value = bestT\n","    self.SplitNode(xL, bestSampleL, node.L)\n","    self.SplitNode(xR, bestSampleR, node.R)\n","  def calcClassP(self, data):\n","    result = np.array([])\n","    for type_ in np.unique(self.y_train):\n","      result = np.append(result, len(data[data == type_]) / len(data))\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6RGqBF8CG1R"},"source":["class DT3:\n","  def __init__(self, depth, minS):\n","    self.tree = None\n","    self.depth = depth\n","    self.nowD = 0\n","    self.minS = minS\n","    self.y_train = None\n","  def findClass(self, x_test, node):\n","    if node.leaf:\n","      return node.classP\n","    elif x_test[node.col] > node.value:\n","      return self.findClass(x_test, node.R)\n","    else:\n","      return self.findClass(x_test, node.L)\n","  def fit(self, x_train, y_train):\n","    self.y_train = y_train\n","    self.tree = Node()\n","    self.tree.classP = self.calcClassP(y_train)\n","    self.SplitNode(np.asarray(x_train), y_train, self.tree)\n","  def predict(self, x_test):\n","    y_pred = np.array([])\n","    for x in np.asarray(x_test):\n","      y_pred = np.append(y_pred, np.argmax(self.findClass(x, self.tree)))\n","    return y_pred\n","  def SplitNode(self, x_train, y_train, node):\n","    if self.nowD >= self.depth or len(np.unique(y_train)) == 1:\n","      node.leaf = True\n","      return\n","    bestFeature = None\n","    bestT = None\n","    bestEntropy = -1\n","    bestSampleL = []\n","    bestSampleR = []\n","    xL = []\n","    xR = []\n","    for feature in range(x_train.shape[1]):\n","      xFeature = x_train[:, feature]\n","      for value in xFeature:\n","        sampleL = y_train[xFeature <= value]\n","        sampleR = y_train[xFeature > value]\n","        if len(sampleL) == 0 or len(sampleR) == 0:\n","          continue\n","        entropyVal = entropy(y_train) - (\n","            (len(sampleL) / len(y_train) * entropy(sampleL)) + (\n","                len(sampleR) / len(y_train)*entropy(sampleR)))\n","        if entropyVal > bestEntropy:\n","          bestT = value\n","          bestEntropy = entropyVal\n","          bestSampleL = sampleL\n","          bestSampleR = sampleR\n","          bestCol = feature\n","          xL = x_train[xFeature <= value, :]\n","          xR = x_train[xFeature > value, :]\n","          xFeature = x_train[:, bestCol]\n","      if len(xL) < self.minS or len(xR) < self.minS:\n","        node.leaf = True\n","        return\n","    self.nowD += 1\n","    node.L = Node()\n","    node.L.classP = self.calcClassP(bestSampleL)\n","    node.R = Node()\n","    node.R.classP = self.calcClassP(bestSampleR)\n","    node.col = bestCol\n","    node.value = bestT\n","    self.SplitNode(xL, bestSampleL, node.L)\n","    self.SplitNode(xR, bestSampleR, node.R)\n","  def calcClassP(self, data):\n","    result = np.array([])\n","    for type_ in np.unique(self.y_train):\n","      result = np.append(result, len(data[data == type_]) / len(data))\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQogNwEDcWfM","executionInfo":{"status":"ok","timestamp":1637833470508,"user_tz":-180,"elapsed":601,"user":{"displayName":"Алексей Бабинцев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16114735127853103545"}},"outputId":"6bf74f28-b795-41d9-8c46-3b96f9f838f1"},"source":["iris = datasets.load_iris()\n","x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.3)\n","dt = DT(5, 5)\n","dt.fit(x_train, y_train)\n","y_pred = dt.predict(x_test)\n","print(f'accuracy score = {accuracy_score(y_test, y_pred)}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy score = 0.9555555555555556\n"]}]},{"cell_type":"markdown","metadata":{"id":"BkyCjLcy_CTM"},"source":["##  Случайный лес"]},{"cell_type":"markdown","metadata":{"id":"7fKZe1FyRgCa"},"source":["Опишем алгоритм случайный лес (*random forest*) и попутно разберём основные идеи:\n","\n","1. Зададим $N$ - число деревьев в лесу.\n","2. Для каждого $n$ из $N$ сгенерируем свою выборку $X_n$. Пусть $m$ - это количество объектов в $X$. При генерации каждой $X_n$ мы будем брать объекты $m$ раз с возвращением. То есть один и тот же объект может попасть в выборку несколько раз, а какие-то объекты не попадут. (Этот способ назвается бутстрап).\n","3. По каждой $X_n$ построим решающее дерево $b_n$. Обычно стараются делать глубокие деревья. В качестве критериев остановки можно использовать `max_depth` или `min_samples_leaf` (например, пока в каждом листе не окажется по одному объекту). При каждом разбиении сначала выбирается $k$ (эвристика $k = \\sqrt d$, где $d$ - это число признаков объектов из выборки $X$) случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них. Обратите внимание, что мы не выбрасываем оставшиеся признаки!\n","4. Итоговый алгоритм будет представлять собой результат голосования (для классификации) и среднее арифметическое (для регрессии). Модификация алгоритма предполагает учёт весов каждого отдельного слабого алгоритма в ансамбле, но в этом особо нет смысла.\n"]},{"cell_type":"markdown","metadata":{"id":"YJBQ8lc0WyrN"},"source":["### Задание 4.2"]},{"cell_type":"markdown","metadata":{"id":"y594Jn04ZTCm"},"source":["В качестве набора данных используйте: https://www.kaggle.com/mathchi/churn-for-bank-customers\n","\n","Там есть описание и примеры работы с этими данными. Если кратко, речь идёт про задачу прогнозирования оттока клиентов. Есть данные о 10 тысячах клиентов банка, часть из которых больше не являются клиентами."]},{"cell_type":"markdown","metadata":{"id":"be_mLbdVW2oG"},"source":["Используя либо свою реализацию, либо  `DecisionTreeClassifier` с разными настройками из `sklearn.tree` реализйте алгоритм \"случайный лес\". \n","\n","Найдите наилучшие гиперпараметры этого алгоритма: количество деревьев, критерий остановки, функционал качества, минимальное количество объектов в листьях и другие.\n","\n","Нельзя использовать готовую реализацию случайного леса из `sklearn`.\n","\n","В подобных задачах очень важна интерпретируемость алгоритма. Попытайтесь оценить информативность признаков, т.е. ответить а вопрос, значения каких признаков являются самыми важными индикаторами того, что банк потеряет клиента."]},{"cell_type":"code","metadata":{"id":"CNQHWALRpLUl"},"source":["class RF:\n","  def __init__(self, tree_count, depth, min_leaves):\n","    self.tree_count = tree_count\n","    self.depth = depth\n","    self.min_leaves = min_leaves\n","    self.trees = []\n","  def fit(self, x_train, y_train):\n","    features = int(np.sqrt(x_train.shape[1]))\n","    for i in range(self.tree_count):\n","      tree = DecisionTreeClassifier(max_features = features, \n","                                    max_depth = self.depth,\n","                                    min_samples_leaf = self.min_leaves)\n","      tree.fit(x_train, y_train)\n","      self.trees.append(tree)\n","  def predict(self, x_test):\n","    result = []\n","    for tree in self.trees:\n","      result.append(tree.predict(x_test))\n","    return round(pd.DataFrame(data = result).mean())\n","  def importances(self):\n","    result = []\n","    for tree in self.trees:\n","      result.append(tree.feature_importances_)\n","    return pd.DataFrame(result).mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"eKcnda9P2MxE","executionInfo":{"status":"ok","timestamp":1637833470902,"user_tz":-180,"elapsed":397,"user":{"displayName":"Алексей Бабинцев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16114735127853103545"}},"outputId":"34d0ccba-e9a0-4de3-c36c-206196eb50a5"},"source":["data = pd.read_csv(r\"/content/drive/MyDrive/ML/churn.csv\")\n","target = data['Exited']\n","data['Gender'] = TargetEncoder().fit_transform(data['Gender'], target)\n","data['Geography'] = TargetEncoder().fit_transform(data['Geography'], target)\n","data = data.drop(['RowNumber', 'CustomerId', 'Surname', 'Exited'], axis = 1)\n","names = data.columns\n","scaler = MinMaxScaler()\n","d = scaler.fit_transform(data)\n","scaled_data = pd.DataFrame(d, columns = names)\n","scaled_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.538</td>\n","      <td>0.00000</td>\n","      <td>1.0</td>\n","      <td>0.324324</td>\n","      <td>0.2</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.506735</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.516</td>\n","      <td>0.03184</td>\n","      <td>1.0</td>\n","      <td>0.310811</td>\n","      <td>0.1</td>\n","      <td>0.334031</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.562709</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.304</td>\n","      <td>0.00000</td>\n","      <td>1.0</td>\n","      <td>0.324324</td>\n","      <td>0.8</td>\n","      <td>0.636357</td>\n","      <td>0.666667</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.569654</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.698</td>\n","      <td>0.00000</td>\n","      <td>1.0</td>\n","      <td>0.283784</td>\n","      <td>0.1</td>\n","      <td>0.000000</td>\n","      <td>0.333333</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.469120</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.000</td>\n","      <td>0.03184</td>\n","      <td>1.0</td>\n","      <td>0.337838</td>\n","      <td>0.2</td>\n","      <td>0.500246</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.395400</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>0.842</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.283784</td>\n","      <td>0.5</td>\n","      <td>0.000000</td>\n","      <td>0.333333</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.481341</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>0.332</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.229730</td>\n","      <td>1.0</td>\n","      <td>0.228657</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.508490</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>0.718</td>\n","      <td>0.00000</td>\n","      <td>1.0</td>\n","      <td>0.243243</td>\n","      <td>0.7</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.210390</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>0.844</td>\n","      <td>1.00000</td>\n","      <td>0.0</td>\n","      <td>0.324324</td>\n","      <td>0.3</td>\n","      <td>0.299226</td>\n","      <td>0.333333</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.464429</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>0.884</td>\n","      <td>0.00000</td>\n","      <td>1.0</td>\n","      <td>0.135135</td>\n","      <td>0.4</td>\n","      <td>0.518708</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.190914</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 10 columns</p>\n","</div>"],"text/plain":["      CreditScore  Geography  ...  IsActiveMember  EstimatedSalary\n","0           0.538    0.00000  ...             1.0         0.506735\n","1           0.516    0.03184  ...             1.0         0.562709\n","2           0.304    0.00000  ...             0.0         0.569654\n","3           0.698    0.00000  ...             0.0         0.469120\n","4           1.000    0.03184  ...             1.0         0.395400\n","...           ...        ...  ...             ...              ...\n","9995        0.842    0.00000  ...             0.0         0.481341\n","9996        0.332    0.00000  ...             1.0         0.508490\n","9997        0.718    0.00000  ...             1.0         0.210390\n","9998        0.844    1.00000  ...             0.0         0.464429\n","9999        0.884    0.00000  ...             0.0         0.190914\n","\n","[10000 rows x 10 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"Hhd_ILakIr6o","executionInfo":{"status":"error","timestamp":1637840833302,"user_tz":-180,"elapsed":2835,"user":{"displayName":"Алексей Бабинцев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16114735127853103545"}},"outputId":"c43a4465-c069-47ff-de83-fc0fd31bf745"},"source":["x_train, x_test, y_train, y_test = train_test_split(scaled_data, target, test_size = 0.3)\n","bestDepth, bestNum, bestMinLeaves, bestScore = 0, 0, 0, 0\n","for num in range(100, 500, 10):\n","  for depth in range(1, 5):\n","    for MinLeaves in range(1, 5):\n","      model = RF(num, depth, MinLeaves)\n","      model.fit(x_train, y_train)\n","      y_pred = model.predict(x_test)\n","      score = accuracy_score(y_test, y_pred)\n","      if score > bestScore:\n","        print(score)\n","        #если новый лучший результат, смотрим скор на тесте\n","        bestDepth, bestNum, bestMinLeaves, bestScore = depth, num, MinLeaves, score\n","print(f'Best:\\ndepth {bestDepth}\\nNum {bestNum}\\nMinLeaves {bestMinLeaves}')\n","model = RF(bestNum, bestDepth, bestMinLeaves)\n","model.fit(x_train, y_train)\n","y_pred = model.predict(x_test)\n","print(f'final score :{accuracy_score(y_test, y_pred)}')"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7926666666666666\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-f705e64b9ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinLeaves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbestScore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-bb89c17f2000>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x_test)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;31m# last ditch effort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OL75UPGfF6e","executionInfo":{"status":"ok","timestamp":1637835315388,"user_tz":-180,"elapsed":2454,"user":{"displayName":"Алексей Бабинцев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16114735127853103545"}},"outputId":"1a235ff1-5f95-4d2f-f949-46724a86a5d2"},"source":["model = RF(230, 4, 2)\n","model.fit(x_train, y_train)\n","y_pred = model.predict(x_test)\n","print(f'final score :{accuracy_score(y_test, y_pred)}')\n","print(pd.DataFrame(data=np.c_[x_test.columns, model.importances()], columns=[\"features\", \"pow\"]).sort_values(by=\"pow\", ascending=False))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["final score :0.848\n","          features          pow\n","3              Age     0.418179\n","6    NumOfProducts     0.337203\n","8   IsActiveMember     0.108735\n","1        Geography    0.0741852\n","5          Balance     0.034692\n","2           Gender    0.0127825\n","0      CreditScore   0.00992237\n","9  EstimatedSalary   0.00255362\n","4           Tenure   0.00135903\n","7        HasCrCard  0.000388575\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-GA9Vzlf1EO","executionInfo":{"status":"ok","timestamp":1637835316357,"user_tz":-180,"elapsed":971,"user":{"displayName":"Алексей Бабинцев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16114735127853103545"}},"outputId":"c5d13f38-2f1a-488f-e1cb-ade6b596b898"},"source":["forest = RandomForestClassifier()\n","forest.fit(x_train, y_train)\n","y_pred = forest.predict(x_test)\n","print(f'{accuracy_score(y_test, y_pred)}')\n","print(pd.DataFrame(data=np.c_[x_test.columns, forest.feature_importances_], columns=[\"features\", \"pow\"]).sort_values(by=\"pow\", ascending=False))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.858\n","          features        pow\n","3              Age   0.232652\n","5          Balance   0.145239\n","9  EstimatedSalary    0.14354\n","0      CreditScore    0.14092\n","6    NumOfProducts   0.134013\n","4           Tenure   0.078012\n","8   IsActiveMember   0.043998\n","1        Geography  0.0429001\n","2           Gender  0.0198844\n","7        HasCrCard  0.0188419\n"]}]}]}